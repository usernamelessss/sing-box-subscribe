import json, os, tool, time, requests, sys, importlib, argparse, yaml, ruamel.yaml
import re
from datetime import datetime
from urllib.parse import urlparse
from collections import OrderedDict
from api.app import TEMP_DIR
from parsers.clash2base64 import clash2v2ray

parsers_mod = {}
providers = None
color_code = [31, 32, 33, 34, 35, 36, 91, 92, 93, 94, 95, 96]


def loop_color(text):
    text = '\033[1;{color}m{text}\033[0m'.format(color=color_code[0], text=text)
    color_code.append(color_code.pop(0))
    return text


def init_parsers():
    b = os.walk('parsers')
    for path, dirs, files in b:
        for file in files:
            f = os.path.splitext(file)
            if f[1] == '.py':
                parsers_mod[f[0]] = importlib.import_module('parsers.' + f[0])


def get_template():
    template_dir = 'config_template'  # é…ç½®æ¨¡æ¿æ–‡ä»¶å¤¹è·¯å¾„
    template_files = os.listdir(template_dir)  # è·å–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    template_list = [os.path.splitext(file)[0] for file in template_files if
                     file.endswith('.json')]  # ç§»é™¤æ‰©å±•åå¹¶è¿‡æ»¤å‡ºä»¥.jsonç»“å°¾çš„æ–‡ä»¶
    template_list.sort()  # å¯¹æ–‡ä»¶åè¿›è¡Œæ’åº
    return template_list


def load_json(path):
    return json.loads(tool.readFile(path))


def process_subscribes(subscribes):
    nodes = {}
    for subscribe in subscribes:
        if 'enabled' in subscribe and not subscribe['enabled']:
            continue
        if 'sing-box-subscribe-doraemon.vercel.app' in subscribe['url']:
            continue
        _nodes = get_nodes(subscribe['url'])
        if _nodes and len(_nodes) > 0:
            add_prefix(_nodes, subscribe)
            add_emoji(_nodes, subscribe)
            nodefilter(_nodes, subscribe)
            if subscribe.get('subgroup'):
                subscribe['tag'] = subscribe['tag'] + '-' + subscribe['subgroup'] + '-' + 'subgroup'
            if not nodes.get(subscribe['tag']):
                nodes[subscribe['tag']] = []
            nodes[subscribe['tag']] += _nodes
        else:
            print('æ²¡æœ‰åœ¨æ­¤è®¢é˜…ä¸‹æ‰¾åˆ°èŠ‚ç‚¹ï¼Œè·³è¿‡')
            # print('KhÃ´ng tÃ¬m tháº¥y proxy trong link thuÃª bao nÃ y, bá» qua')
    tool.proDuplicateNodeName(nodes)
    return nodes


def nodes_filter(nodes, filter, group):
    for a in filter:
        if a.get('for') and group not in a['for']:
            continue
        nodes = action_keywords(nodes, a['action'], a['keywords'])
    return nodes


def action_keywords(nodes, action, keywords):
    # filterå°†æŒ‰é¡ºåºä¾æ¬¡æ‰§è¡Œ
    # "filter":[
    #         {"action":"include","keywords":[""]},
    #         {"action":"exclude","keywords":[""]}
    #     ]
    temp_nodes = []
    flag = False
    if action == 'exclude':
        flag = True
    '''
    # ç©ºå…³é”®å­—è¿‡æ»¤
    '''
    # Join the patterns list into a single pattern, separated by '|'
    combined_pattern = '|'.join(keywords)

    # If the combined pattern is empty or only contains whitespace, return the original nodes
    if not combined_pattern or combined_pattern.isspace():
        return nodes

    # Compile the combined regex pattern
    compiled_pattern = re.compile(combined_pattern)

    for node in nodes:
        name = node['tag']
        # Use regex to check for a match
        match_flag = bool(compiled_pattern.search(name))

        # Use XOR to decide if the node should be included based on the action
        if match_flag ^ flag:
            temp_nodes.append(node)

    return temp_nodes


def add_prefix(nodes, subscribe):
    if subscribe.get('prefix'):
        for node in nodes:
            node['tag'] = subscribe['prefix'] + node['tag']
            if node.get('detour'):
                node['detour'] = subscribe['prefix'] + node['detour']


def add_emoji(nodes, subscribe):
    if subscribe.get('emoji'):
        for node in nodes:
            node['tag'] = tool.rename(node['tag'])
            if node.get('detour'):
                node['detour'] = tool.rename(node['detour'])


def nodefilter(nodes, subscribe):
    if subscribe.get('ex-node-name'):
        ex_nodename = re.split(r'[,\|]', subscribe['ex-node-name'])
        for exns in ex_nodename:
            for node in nodes[:]:  # éå† nodes çš„å‰¯æœ¬ï¼Œä»¥ä¾¿å®‰å…¨åœ°åˆ é™¤å…ƒç´ 
                if exns in node['tag']:
                    nodes.remove(node)


def get_nodes(url):
    if url.startswith('sub://'):
        url = tool.b64Decode(url[6:]).decode('utf-8')
    urlstr = urlparse(url)
    if not urlstr.scheme:
        try:
            content = tool.b64Decode(url).decode('utf-8')
            data = parse_content(content)
            processed_list = []
            for item in data:
                if isinstance(item, tuple):
                    processed_list.extend([item[0], item[1]])  # å¤„ç†shadowtls
                else:
                    processed_list.append(item)
            return processed_list
        except:
            content = get_content_form_file(url)
    else:
        content = get_content_from_url(url)
    # print (content)
    if type(content) == dict:
        if 'proxies' in content:
            share_links = []
            # éå†ä»£ç†ä¿¡æ¯
            note_count = 0
            for proxy in content['proxies']:
                note_count += 1
                proxy_name = proxy['name']
                proxy_protocol = proxy['type']
                # ç‰¹æ®ŠèŠ‚ç‚¹é‡å‘½å
                if "å®˜ç½‘" in proxy_name and "superflash" in proxy_name:
                    proxy['name'] = "â™¥ï¸ å®˜ç½‘æ¨èèŠ‚ç‚¹"
                if "å¤‡ç”¨" in proxy_name and "superflash" in proxy_name:
                    proxy['name'] = "ğŸ’Š å®˜ç½‘å¤‡ç”¨èŠ‚ç‚¹ 1ï¸âƒ£"
                if "è¿ä¸ä¸Š" in proxy_name and "å°è¯•æ›´æ–°" in proxy_name:
                    proxy['name'] = "ğŸ’Š å®˜ç½‘å¤‡ç”¨èŠ‚ç‚¹ 2ï¸âƒ£"
                if "æœ‰é—®é¢˜" in proxy_name and "è”ç³»å®¢æœ" in proxy_name:
                    proxy['name'] = "ğŸ’Š å®˜ç½‘å¤‡ç”¨èŠ‚ç‚¹ 3ï¸âƒ£"
                if "å®˜ç½‘" in proxy_name and "å¼€å…³" in proxy_name:
                    proxy['name'] = "ğŸ’Š å®˜ç½‘å¤‡ç”¨èŠ‚ç‚¹ 4ï¸âƒ£"
                print('     \33[36;1mã€{0}\033[0m \33[35;1m{1}\033[0m åè®®èŠ‚ç‚¹ã€‘'.format(proxy_name, proxy_protocol))
                share_links.append(clash2v2ray(proxy))
            print('\33[31;1mè·å–çš„èŠ‚ç‚¹æ•°é‡ä¸º:{0}'.format(note_count))
            data = '\n'.join(share_links)
            data = parse_content(data)
            processed_list = []
            for item in data:
                if isinstance(item, tuple):
                    processed_list.extend([item[0], item[1]])  # å¤„ç†shadowtls
                else:
                    processed_list.append(item)
            return processed_list
        elif 'outbounds' in content:
            outbounds = []
            excluded_types = {"selector", "urltest", "direct", "block", "dns"}
            filtered_outbounds = [outbound for outbound in content['outbounds'] if
                                  outbound.get("type") not in excluded_types]
            outbounds.extend(filtered_outbounds)
            return outbounds
    else:
        data = parse_content(content)
        processed_list = []
        for item in data:
            if isinstance(item, tuple):
                processed_list.extend([item[0], item[1]])  # å¤„ç†shadowtls
            else:
                processed_list.append(item)
        return processed_list


def parse_content(content):
    # firstline = tool.firstLine(content)
    # # print(firstline)
    # if not get_parser(firstline):
    #     return None
    nodelist = []
    for t in content.splitlines():
        t = t.strip()
        if len(t) == 0:
            continue
        factory = get_parser(t)
        if not factory:
            continue
        try:
            node = factory(t)
        except Exception as e:  # èŠ‚ç‚¹è§£æå¤±è´¥ï¼Œè·³è¿‡
            pass
        if node:
            nodelist.append(node)
    return nodelist


def get_parser(node):
    proto = tool.get_protocol(node)
    if providers.get('exclude_protocol'):
        eps = providers['exclude_protocol'].split(',')
        if len(eps) > 0:
            eps = [protocol.strip() for protocol in eps]
            if 'hy2' in eps:
                index = eps.index('hy2')
                eps[index] = 'hysteria2'
            if proto in eps:
                return None
    if not proto or proto not in parsers_mod.keys():
        return None
    return parsers_mod[proto].parse


def get_content_from_url(url, n=10):
    UA = ''
    print('å¤„ç†: \033[34;4m' + url + '\033[0m')
    prefixes = ["vmess://", "vless://", "ss://", "ssr://", "trojan://", "tuic://", "hysteria://", "hysteria2://",
                "hy2://", "wg://", "wireguard://", "http2://", "socks://", "socks5://"]
    if any(url.startswith(prefix) for prefix in prefixes):
        response_text = tool.noblankLine(url)
        return response_text
    for subscribe in providers["subscribes"]:
        if 'enabled' in subscribe and not subscribe['enabled']:
            continue
        if subscribe['url'] == url:
            UA = subscribe.get('User-Agent', '')
    response = tool.getResponse(url, custom_user_agent=UA)
    concount = 1
    while concount <= n and not response:
        print('è¿æ¥å‡ºé”™ï¼Œæ­£åœ¨è¿›è¡Œç¬¬ ' + str(concount) + ' æ¬¡é‡è¯•ï¼Œæœ€å¤šé‡è¯• ' + str(n) + ' æ¬¡...')
        # print('Lá»—i káº¿t ná»‘i, Ä‘ang thá»­ láº¡i '+str(concount)+'/'+str(n)+'...')
        response = tool.getResponse(url)
        concount = concount + 1
        time.sleep(1)
    if not response:
        print('è·å–é”™è¯¯ï¼Œè·³è¿‡æ­¤è®¢é˜…')
        # print('Lá»—i khi táº£i link Ä‘Äƒng kÃ½, bá» qua link Ä‘Äƒng kÃ½ nÃ y')
        print('----------------------------')
        pass
    try:
        response_content = response.content
        response_text = response_content.decode('utf-8-sig')  # utf-8-sig å¯ä»¥å¿½ç•¥ BOM
        # response_encoding = response.encoding
    except:
        return ''
    if response_text.isspace():
        print('æ²¡æœ‰ä»è®¢é˜…é“¾æ¥è·å–åˆ°ä»»ä½•å†…å®¹')
        # print('KhÃ´ng nháº­n Ä‘Æ°á»£c proxy nÃ o tá»« link Ä‘Äƒng kÃ½')
        return None
    if not response_text:
        response = tool.getResponse(url, custom_user_agent='clashmeta')
        response_text = response.text
    if any(response_text.startswith(prefix) for prefix in prefixes):
        response_text = tool.noblankLine(response_text)
        return response_text
    elif 'proxies' in response_text:
        yaml_content = response.content.decode('utf-8')
        response_text_no_tabs = yaml_content.replace('\t', ' ')  # fuckU
        yaml = ruamel.yaml.YAML()
        try:
            response_text = dict(yaml.load(response_text_no_tabs))
            return response_text
        except:
            pass
    elif 'outbounds' in response_text:
        try:
            response_text = json.loads(response.text)
            return response_text
        except:
            response_text = re.sub(r'//.*', '', response_text)
            response_text = json.loads(response_text)
            return response_text
    else:
        try:
            response_text = tool.b64Decode(response_text)
            response_text = response_text.decode(encoding="utf-8")
            # response_text = bytes.decode(response_text,encoding=response_encoding)
        except:
            pass
            # traceback.print_exc()
    return response_text


def get_content_form_file(url):
    print('å¤„ç†: \033[31m' + url + '\033[0m')
    file_extension = os.path.splitext(url)[1]  # è·å–æ–‡ä»¶çš„åç¼€å
    if file_extension.lower() == '.yaml':
        with open(url, 'rb') as file:
            content = file.read()
        yaml_data = dict(yaml.safe_load(content))
        share_links = []
        for proxy in yaml_data['proxies']:
            share_links.append(clash2v2ray(proxy))
        node = '\n'.join(share_links)
        processed_list = tool.noblankLine(node)
        return processed_list
    else:
        data = tool.readFile(url)
        data = bytes.decode(data, encoding='utf-8')
        data = tool.noblankLine(data)
        return data


def save_config(path, nodes):
    try:
        if 'auto_backup' in providers and providers['auto_backup']:
            now = datetime.now().strftime('%Y%m%d%H%M%S')
            if os.path.exists(path):
                os.rename(path, f'{path}.{now}.bak')
        if os.path.exists(path):
            os.remove(path)
            print(f"\033[37må·²åˆ é™¤æ–‡ä»¶ï¼Œå¹¶é‡æ–°ä¿å­˜ï¼š\033[0m\033[33m{path}\033[0m")
            # print(f"File cáº¥u hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o: \033[33m{path}\033[0m")
        else:
            print(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä¿å­˜ï¼š\033[33m{path}\033[0m")
            # print(f"File khÃ´ng tá»“n táº¡i, Ä‘ang lÆ°u táº¡i: \033[33m{path}\033[0m")
        tool.saveFile(path, json.dumps(nodes, indent=2, ensure_ascii=False))
    except Exception as e:
        print(f"ä¿å­˜é…ç½®æ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}")
        # print(f"Lá»—i khi lÆ°u file cáº¥u hÃ¬nh: {str(e)}")
        # å¦‚æœä¿å­˜å‡ºé”™ï¼Œå°è¯•ä½¿ç”¨ config_file_path å†æ¬¡ä¿å­˜
        config_path = json.loads(temp_json_data).get("save_config_path", "config.json")
        CONFIG_FILE_NAME = config_path
        config_file_path = os.path.join('/tmp', CONFIG_FILE_NAME)
        try:
            if os.path.exists(config_file_path):
                os.remove(config_file_path)
                print(f"å·²åˆ é™¤æ–‡ä»¶ï¼Œå¹¶é‡æ–°ä¿å­˜ï¼š\033[33m{config_file_path}\033[0m")
                # print(f"File cáº¥u hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o: \033[33m{config_file_path}\033[0m")
            else:
                print(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä¿å­˜ï¼š\033[33m{config_file_path}\033[0m")
                # print(f"File khÃ´ng tá»“n táº¡i, Ä‘ang lÆ°u táº¡i: \033[33m{config_file_path}\033[0m")
            tool.saveFile(config_file_path, json.dumps(nodes, indent=2, ensure_ascii=False))
            # print(f"é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ° {config_file_path}")
            # print(f"Táº­p tin cáº¥u hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o {config_file_path}")
        except Exception as e:
            os.remove(config_file_path)
            print(f"å·²åˆ é™¤æ–‡ä»¶ï¼š\033[33m{config_file_path}\033[0m")
            # print(f"CÃ¡c file Ä‘Ã£ bá»‹ xÃ³a: \033[33m{config_file_path}\033[0m")
            print(f"å†æ¬¡ä¿å­˜é…ç½®æ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}")
            # print(f"Lá»—i khi lÆ°u láº¡i file cáº¥u hÃ¬nh: {str(e)}")


def set_proxy_rule_dns(config):
    # dns_template = {
    #     "tag": "remote",
    #     "address": "tls://1.1.1.1",
    #     "detour": ""
    # }
    config_rules = config['route']['rules']
    outbound_dns = []
    dns_rules = config['dns']['rules']
    asod = providers["auto_set_outbounds_dns"]
    for rule in config_rules:
        if rule['outbound'] not in ['block', 'dns-out']:
            if rule['outbound'] != 'direct':
                outbounds_dns_template = \
                    list(filter(lambda server: server['tag'] == asod["proxy"], config['dns']['servers']))[0]
                dns_obj = outbounds_dns_template.copy()
                dns_obj['tag'] = rule['outbound'] + '_dns'
                dns_obj['detour'] = rule['outbound']
                if dns_obj not in outbound_dns:
                    outbound_dns.append(dns_obj)
            if rule.get('type') and rule['type'] == 'logical':
                dns_rule_obj = {
                    'type': 'logical',
                    'mode': rule['mode'],
                    'rules': [],
                    'server': rule['outbound'] + '_dns' if rule['outbound'] != 'direct' else asod["direct"]
                }
                for _rule in rule['rules']:
                    child_rule = pro_dns_from_route_rules(_rule)
                    if child_rule:
                        dns_rule_obj['rules'].append(child_rule)
                if len(dns_rule_obj['rules']) == 0:
                    dns_rule_obj = None
            else:
                dns_rule_obj = pro_dns_from_route_rules(rule)
            if dns_rule_obj:
                dns_rules.append(dns_rule_obj)
    # æ¸…é™¤é‡å¤è§„åˆ™
    _dns_rules = []
    for dr in dns_rules:
        if dr not in _dns_rules:
            _dns_rules.append(dr)
    config['dns']['rules'] = _dns_rules
    config['dns']['servers'].extend(outbound_dns)


def pro_dns_from_route_rules(route_rule):
    dns_route_same_list = ["inbound", "ip_version", "network", "protocol", 'domain', 'domain_suffix', 'domain_keyword',
                           'domain_regex', 'geosite', "source_geoip", "source_ip_cidr", "source_port",
                           "source_port_range", "port", "port_range", "process_name", "process_path", "package_name",
                           "user", "user_id", "clash_mode", "invert"]
    dns_rule_obj = {}
    for key in route_rule:
        if key in dns_route_same_list:
            dns_rule_obj[key] = route_rule[key]
    if len(dns_rule_obj) == 0:
        return None
    if route_rule.get('outbound'):
        dns_rule_obj['server'] = route_rule['outbound'] + '_dns' if route_rule['outbound'] != 'direct' else \
            providers["auto_set_outbounds_dns"]['direct']
    return dns_rule_obj


def pro_node_template(data_nodes, config_outbound, group):
    if config_outbound.get('filter'):
        data_nodes = nodes_filter(data_nodes, config_outbound['filter'], group)
    return [node.get('tag') for node in data_nodes]


def combin_to_config(config, data):
    config_outbounds = config["outbounds"] if config.get("outbounds") else None
    i = 0
    for group in data:
        if 'subgroup' in group:
            i += 1
            for out in config_outbounds:
                if out.get("outbounds"):
                    if out['tag'] == 'Proxy':
                        out["outbounds"] = [out["outbounds"]] if isinstance(out["outbounds"], str) else out["outbounds"]
                        if '{all}' in out["outbounds"]:
                            index_of_all = out["outbounds"].index('{all}')
                            out["outbounds"][index_of_all] = (group.rsplit("-", 1)[0]).rsplit("-", 1)[-1]
                            i += 1
                        else:
                            out["outbounds"].insert(i, (group.rsplit("-", 1)[0]).rsplit("-", 1)[-1])
            new_outbound = {'tag': (group.rsplit("-", 1)[0]).rsplit("-", 1)[-1], 'type': 'selector',
                            'outbounds': ['{' + group + '}']}
            config_outbounds.insert(-2, new_outbound)
            if 'subgroup' not in group:
                for out in config_outbounds:
                    if out.get("outbounds"):
                        if out['tag'] == 'Proxy':
                            out["outbounds"] = [out["outbounds"]] if isinstance(out["outbounds"], str) else out[
                                "outbounds"]
                            out["outbounds"].append('{' + group + '}')
    temp_outbounds = []
    if config_outbounds:
        # æå‰å¤„ç†allæ¨¡æ¿
        for po in config_outbounds:
            # å¤„ç†å‡ºç«™
            if po.get("outbounds"):
                if '{all}' in po["outbounds"]:
                    o1 = []
                    for item in po["outbounds"]:
                        if item.startswith('{') and item.endswith('}'):
                            _item = item[1:-1]
                            if _item == 'all':
                                o1.append(item)
                        else:
                            o1.append(item)
                    po['outbounds'] = o1
                t_o = []
                check_dup = []
                for oo in po["outbounds"]:
                    # é¿å…æ·»åŠ é‡å¤èŠ‚ç‚¹
                    if oo in check_dup:
                        continue
                    else:
                        check_dup.append(oo)
                    # å¤„ç†æ¨¡æ¿
                    if oo.startswith('{') and oo.endswith('}'):
                        oo = oo[1:-1]
                        if data.get(oo):
                            nodes = data[oo]
                            t_o.extend(pro_node_template(nodes, po, oo))
                        else:
                            if oo == 'all':
                                for group in data:
                                    nodes = data[group]
                                    t_o.extend(pro_node_template(nodes, po, group))
                    else:
                        t_o.append(oo)
                if len(t_o) == 0:
                    t_o.append('Proxy')
                    print('å‘ç° {} å‡ºç«™ä¸‹çš„èŠ‚ç‚¹æ•°é‡ä¸º 0 ï¼Œä¼šå¯¼è‡´sing-boxæ— æ³•è¿è¡Œï¼Œè¯·æ£€æŸ¥configæ¨¡æ¿æ˜¯å¦æ­£ç¡®ã€‚'.format(
                        po['tag']))
                    # print('Sing-Box khÃ´ng cháº¡y Ä‘Æ°á»£c vÃ¬ khÃ´ng tÃ¬m tháº¥y báº¥t ká»³ proxy nÃ o trong outbound cá»§a {}. Vui lÃ²ng kiá»ƒm tra xem máº«u cáº¥u hÃ¬nh cÃ³ Ä‘Ãºng khÃ´ng!!'.format(po['tag']))
                    """
                    config_path = json.loads(temp_json_data).get("save_config_path", "config.json")
                    CONFIG_FILE_NAME = config_path
                    config_file_path = os.path.join('/tmp', CONFIG_FILE_NAME)
                    if os.path.exists(config_file_path):
                        os.remove(config_file_path)
                        print(f"å·²åˆ é™¤æ–‡ä»¶ï¼š{config_file_path}")
                        # print(f"CÃ¡c táº­p tin Ä‘Ã£ bá»‹ xÃ³a: {config_file_path}")
                    sys.exit()
                    """
                po['outbounds'] = t_o
                if po.get('filter'):
                    del po['filter']
    for group in data:
        temp_outbounds.extend(data[group])
    config['outbounds'] = config_outbounds + temp_outbounds
    # è‡ªåŠ¨é…ç½®è·¯ç”±è§„åˆ™åˆ°dnsè§„åˆ™ï¼Œé¿å…dnsæ³„éœ²
    dns_tags = [server.get('tag') for server in config['dns']['servers']]
    asod = providers.get("auto_set_outbounds_dns")
    if asod and asod.get('proxy') and asod.get('direct') and asod['proxy'] in dns_tags and asod['direct'] in dns_tags:
        set_proxy_rule_dns(config)
    # æå– wireguard ç±»å‹å†…å®¹
    wireguard_items = [item for item in config['outbounds'] if item.get('type') == 'wireguard']
    if wireguard_items:
        endpoints = []
        for item in wireguard_items:
            endpoints.append(item)
        new_config = OrderedDict()
        for key, value in config.items():
            new_config[key] = value
            if key == 'outbounds':  # åœ¨ outbounds åé¢æ’å…¥ endpoint
                new_config['endpoints'] = endpoints
        config = new_config
        # æ›´æ–° outboundsï¼Œç§»é™¤ wireguard ç±»å‹
        config['outbounds'] = [item for item in config['outbounds'] if item.get('type') != 'wireguard']
    return config


def updateLocalConfig(local_host, path):
    header = {
        'Content-Type': 'application/json'
    }
    r = requests.put(local_host + '/configs?force=false', json={"path": path}, headers=header)
    print(r.text)


def display_template(tl):
    print_str = ''
    for i in range(len(tl)):
        print_str += loop_color('{index}ã€{name} '.format(index=i + 1, name=tl[i]))
    print(print_str)


def select_config_template(tl, selected_template_index=None):
    if args.template_index is not None:
        uip = args.template_index
    else:
        # print ('Nháº­p sá»‘ Ä‘á»ƒ chá»n máº«u cáº¥u hÃ¬nh tÆ°Æ¡ng á»©ng (nháº¥n Enter Ä‘á»ƒ chá»n máº«u cáº¥u hÃ¬nh Ä‘áº§u tiÃªn theo máº·c Ä‘á»‹nh): ')
        uip = input('è¾“å…¥åºå·ï¼Œè½½å…¥å¯¹åº”configæ¨¡æ¿ï¼ˆç›´æ¥å›è½¦é»˜è®¤é€‰ç¬¬ä¸€ä¸ªé…ç½®æ¨¡æ¿ï¼‰ï¼š')
        try:
            if uip == '':
                return 0
            uip = int(uip)
            if uip < 1 or uip > len(tl):
                print('è¾“å…¥äº†é”™è¯¯ä¿¡æ¯ï¼é‡æ–°è¾“å…¥')
                # print('Nháº­p thÃ´ng tin khÃ´ng chÃ­nh xÃ¡c! Vui lÃ²ng nháº­p láº¡i')
                return select_config_template(tl)
            else:
                uip -= 1
        except:
            print('è¾“å…¥äº†é”™è¯¯ä¿¡æ¯ï¼é‡æ–°è¾“å…¥')
            # print('Nháº­p thÃ´ng tin khÃ´ng chÃ­nh xÃ¡c! Vui lÃ²ng nháº­p láº¡i')
            return select_config_template(tl)
    return uip


# è‡ªå®šä¹‰å‡½æ•°ï¼Œç”¨äºè§£æå‚æ•°ä¸º JSON æ ¼å¼
def parse_json(value):
    try:
        return json.loads(value)
    except json.JSONDecodeError:
        raise argparse.ArgumentTypeError(f"Invalid JSON: {value}")


if __name__ == '__main__':
    init_parsers()
    parser = argparse.ArgumentParser()
    parser.add_argument('--temp_json_data', type=parse_json, help='ä¸´æ—¶å†…å®¹')
    parser.add_argument('--template_index', type=int, help='æ¨¡æ¿åºå·')
    args = parser.parse_args()
    temp_json_data = args.temp_json_data
    if temp_json_data and temp_json_data != '{}':
        providers = json.loads(temp_json_data)
    else:
        # providers = load_json('providers.json')  # åŠ è½½æœ¬åœ° providers.json
        providers = load_json('providers_now.json')  # åŠ è½½æœ¬åœ° providers.json
    # é…ç½®ä¸­è·å–æ¨¡æ¿å‚æ•°
    local_template_config = providers.get('local_config_template')
    remote_template_config = providers.get('config_template')
    if remote_template_config:
        config_template_path = providers['config_template']
        print('é€‰æ‹©: \033[33m' + config_template_path + '\033[0m')
        response = requests.get(providers['config_template'])
        response.raise_for_status()
        config = response.json()
    elif local_template_config:
        comment = providers['local_config_template_comment']
        print('\033[32;1m{0}'.format(comment))
        config = load_json(local_template_config)
    else:
        template_list = get_template()
        if len(template_list) < 1:
            print('æ²¡æœ‰æ‰¾åˆ°æ¨¡æ¿æ–‡ä»¶')
            # print('KhÃ´ng tÃ¬m tháº¥y file máº«u')
            sys.exit()
        display_template(template_list)
        uip = select_config_template(template_list, selected_template_index=args.template_index)
        config_template_path = 'config_template/' + template_list[uip] + '.json'
        print('é€‰æ‹©: \033[33m' + template_list[uip] + '.json\033[0m')
        # print ('Máº«u cáº¥u hÃ¬nh sá»­ dá»¥ng: \033[33m' + template_list[uip] + '.json\033[0m')
        config = load_json(config_template_path)
    nodes = process_subscribes(providers["subscribes"])
    if providers.get('Only-nodes'):
        combined_contents = []
        for sub_tag, contents in nodes.items():
            # éå†æ¯ä¸ªæœºåœºçš„å†…å®¹
            for content in contents:
                # å°†å†…å®¹æ·»åŠ åˆ°æ–°åˆ—è¡¨ä¸­
                combined_contents.append(content)
        final_config = combined_contents  # åªè¿”å›èŠ‚ç‚¹ä¿¡æ¯
    else:
        final_config = combin_to_config(config, nodes)  # èŠ‚ç‚¹ä¿¡æ¯æ·»åŠ åˆ°æ¨¡æ¿
    save_config(providers["save_config_path"], final_config)
    # updateLocalConfig('http://127.0.0.1:9090',providers['save_config_path'])
